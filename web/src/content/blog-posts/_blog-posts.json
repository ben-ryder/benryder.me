{
  "data": [
    {
      "content": "## Linux Setup\nThis is my linux setup.",
      "date_created": "2023-10-07T11:19:33.659Z",
      "date_updated": "2024-05-13T16:42:45.005Z",
      "description": "An ever evolving guide to my Linux setup including some useful scripts and solutions to common issues I've come across.",
      "featured": false,
      "id": "34e62dd5-5fdb-46d3-8229-1ee86ba1876a",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "linux-setup",
      "status": "idea",
      "title": "Linux Setup",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        4
      ]
    },
    {
      "content": "Writing code is a balance between art and science. \n\nThere are good practices, there are bad practices, but there are no perfect practises. As ever... it depends.\n\nJust as a painting may be a delicate mix between colour and shape crafted into something beuatify, so might code be called a painting, a purposful and elegant mix of technical solution, style, debt and compramise. \n\n\n## Care about your code\nApathy is the enemy of all problems. The most important way to write testable code is for you or your team to care about doing it.\nThis sounds obvious and silly, but I think it's an important point to open with.\nIt is unfair to paint developers as lazy \n\n## Testing first, testing always\n- use TDD if possible\n- Treat tests as part of your product, write tests with the same care and attention as your product code, and treat them as a first class concern when making changes \n\n---\n## Prefer testing behaviours over implementations\nWrite E2E style tests where possible first, then use unit and integration testing to fill in gaps and pick up areas which are hard to E2E test.\nThis makes your tests more resilient to refactoring and means you're testing like the actual experiences your product\n\n---\n## Separate dependencies and code\nUse techniques like dependency injection to separate and isolate your code into easily testable chunks. This can also help you test one thing at a time.\n\nIf using something like React, attempt to keep strict boundaries between state, logic and visual display. \n\n---\n## Prefer restructuring code over using internals when writing tests\nPrefer restructuring code in your application to employing tools like spying, mocking etc as these add extra complexity and may indicate a different code or test structure would work better.\n\nfor example, rather than testing reading/writing data by spying on a called method you could just try to retrieve the data again and check it is correct.",
      "date_created": "2024-11-27T16:38:47.142Z",
      "date_updated": null,
      "description": "How can you write testable code?",
      "featured": false,
      "id": "3703052f-80fa-41a5-a912-ed2b2d61785f",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "writing-testable-code",
      "status": "draft",
      "title": "Writing testable code",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    },
    {
      "content": "Local-First Software",
      "date_created": "2023-10-07T11:19:33.675Z",
      "date_updated": "2024-11-27T16:22:19.978Z",
      "description": "Local-First Software",
      "featured": true,
      "id": "56eebb94-7afa-4bcd-9e16-0df29a91ae3c",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "local-first",
      "status": "idea",
      "title": "Local-First Software",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        12
      ]
    },
    {
      "content": "While developing a Electron based markdown editor - similar to [Mark Text](https://marktext.app/) and [Zettlr](https://www.zettlr.com/) - to practice using Electron, I came across the need to read the folder structure of a supplied folder to display the files in a sidebar to the user.\n\nI had a google around, however all examples I could find to recursively load in the folder structure (all files in the supplied folder and all sub folders) were returning a flat list of file paths, which for my use case was loosing valuable data about the folder structure.\n\nThe best solution I found for loading files recursively was from [coderrocketfuel.com](https://coderrocketfuel.com/article/recursively-list-all-the-files-in-a-directory-using-node-js):\n\n```js\nconst fs = require(\"fs\")\nconst path = require(\"path\")\n\nconst getAllFiles = function(dirPath, arrayOfFiles) {\n  files = fs.readdirSync(dirPath)\n\n  arrayOfFiles = arrayOfFiles || []\n\n  files.forEach(function(file) {\n    if (fs.statSync(dirPath + \"/\" + file).isDirectory()) {\n      arrayOfFiles = getAllFiles(dirPath + \"/\" + file, arrayOfFiles)\n    } else {\n      arrayOfFiles.push(path.join(__dirname, dirPath, \"/\", file))\n    }\n  })\n\n  return arrayOfFiles\n```\n\nTheir solution ends up returning an array of files. While this is good, for my use case I wanted to retain the folder structure data so I can use it later in the sidebar for functionality such as expand and collapse folders.\n\nI decided to use the following data structure to represent a folder:\n\n```js\nlet folder = {\n    name: \"folder\",\n    path: \"/path/to/folder\",\n    files: [], // A list of file objects (see below)\n    children: [], // A list folders objects sharing the same structure.\n}\n\nlet file = {\n    name: \"filename\",\n    path: \"path/to/the/filename\"\n}\n```\n\nJust a note, I know that the \"name\" field on the folder and file object is technically already stored in the path, but I felt it made more sense to process it here once rather than having to work it out on the fly when needed.\n\nI then just had to replace the `arrayOfFiles` in the above example with my new folder data structure. A few edits - and some extra edits specifically for my project such as the allowed file extensions check - got me the following:\n\n```js\n\nconst fs = require(\"fs\")\nconst path = require(\"path\")\n\nconst allowedFileExtensions = [\".md\"]\n\nfunction loadDirectoryStructure(directoryPath, parentFolder){\n        let files = fs.readdirSync(directoryPath)\n        parentFolder = parentFolder || {\n            name: path.basename(directoryPath),\n            path: directoryPath,\n            files: [],\n            children: [],\n        }\n\n        files.forEach(file => {\n            let filePath = directoryPath + path.sep + file\n            if (fs.statSync(filePath).isDirectory()) {\n                parentFolder.children.push(this.loadDirectoryStructure(filePath))\n            }\n            else {\n                if(allowedFileExtensions.includes(path.extname(filePath))){\n                    parentFolder.files.push({\n                        name: path.basename(filePath),\n                        path: filePath\n                    })\n                }\n            }\n        })\n\n        return parentFolder\n    }\n```\n\nThis function can now take a folder path, and will output a folder object that retains the folder structure while you are still able to access all the file and folder paths\n\nI'm not saying that this is the best or only way to achieve this, but it's what I decided to use and it's working for me so far!",
      "date_created": "2023-10-07T11:19:33.698Z",
      "date_updated": "2023-10-07T14:58:58.798Z",
      "description": "An explanation and code example of how you can recursively read a folders structure with Node.js.",
      "featured": false,
      "id": "5a98b5ca-d901-4682-b98b-6e39941e26ab",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "recursively-reading-a-folder-structure-in-nodejs",
      "status": "published",
      "title": "Recursively reading a folder structure in Node.js",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        1
      ]
    },
    {
      "content": "Using cellular automata to generate a random map",
      "date_created": "2023-10-07T11:19:33.788Z",
      "date_updated": "2023-10-14T21:53:46.376Z",
      "description": "Using cellular automata to generate a random map",
      "featured": false,
      "id": "7e39ba4f-cc93-476c-bafc-7ab9466efab4",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "using-cellular-automata-to-generate-a-random-map",
      "status": "idea",
      "title": "Using cellular automata to generate a random map",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        10
      ]
    },
    {
      "content": "This aims to be a collection of \"Uncommon common\" git operations, meaning they are relatively uncommon operations that I find myself searching for often enough to write them down somewhere.\nThis is in no way meant to be an exhaustive list, just a reference for myself that might be useful to others.\n\n**Contents:**\n- [Apply the latest gitignore changes](#apply-the-latest-gitignore-changes)\n- [Moving a commit to a different branch](#moving-a-commit-to-a-different-branch)\n- [Ensure all commits share the same author](#ensure-all-commits-share-the-same-author)\n\n## Apply the latest gitignore changes\nIf you make gitignore changes it's possible that your repository will need to be \"refreshed\" for all rules to apply, especially if you add rules for files that are currently being tracked by git.\nTo ensure your repository is up to date with the latest gitignore changes you can run the following commands:\n\n```bash\ngit rm -r --cached .\ngit add .\ngit commit -m \"Updating repo with gitignore changes.\"  \n```\n\n**Note: It's important that you commit or stash all work prior to running these commands as you will lose all untracked changes.**\n\n## Moving a commit to a different branch \nEvery now and again it's possible you may commit directly to the `master` or `develop` branch forgetting to create a feature branch first. Luckily - assuming you haven't pushed the changes yet - it's quick and painless to move that commit to a feature branch.\n\nIf `<base-branch>` contains 1 rogue commit you want to move to `<new-feature-branch>` then you can run the following:\n\n```bash\ngit checkout -b <new-feature-branch>\ngit reset --hard HEAD~1 <base-branch>\n```\n\nIf you have more than one commit to undo you can change `HEAD~1` to use a different number.\nThis operation rewrites the base branch history which may cause issues if the branch has already been pushed. In these cases you could use the `--force` flag to force overwrite history however if there are other developers on the project you should avoid that and use `git revert` or similar instead.\n\n## Ensure all commits share the same author\nThere are times where you might forget to change your git user config before working on a project.\nIf you have already pushed your commit, this is a quick and dirty way to effectively ensure all commits in your project share the same user name and email:\n\n```bash\ngit filter-branch -f --env-filter \"GIT_AUTHOR_NAME='<name>'; GIT_AUTHOR_EMAIL='<email>'; GIT_COMMITTER_NAME='<name>'; GIT_COMMITTER_EMAIL='<email>';\" HEAD;\ngit push --force origin <current-branch>\n```\n\n**Important Note: This is force pushing a history rewrite. You should only really use it on a project where you are the only developer and/or you know this won't effect anyone else.**",
      "date_created": "2023-10-07T11:19:33.773Z",
      "date_updated": "2023-10-14T21:50:55.410Z",
      "description": "A collection of git operations I find myself searching for surprisingly often.",
      "featured": false,
      "id": "8170956f-64f5-4dcb-bfd2-0848c7719671",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "uncommon-common-git-operations",
      "status": "published",
      "title": "Uncommon Common Git Operations",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        3
      ]
    },
    {
      "content": "In order to practise various coding skills I've recently been developing a Reddit ingest system. This system would periodically 'ingest' the posts you've saved to your Reddit account and do something with them. This could be useful in a number of ways:\n- If you've saved a post containing an article you want to read later the system could automatically add it to a todo list somewhere.\n- If a saved post contains a Youtube video the system could add it to your 'watch later' playlist.\n- If you have an obsession with saving funny cat pictures the system could automatically extract the pictures and download them for your vast hord.\n\nThinking this system though I quickly noticed an interesting structural problem I'd have to solve.\nAs you can see in my list above, there could be many different ways this system could be expanded and used.\nIt wouldn't make sense to start commiting custom solutions to the source code as these might only be useful in one instance. I would therefore need to develop a solution which could be customized for specific use cases while retaining a common internal system. So I turned to hooks.\n\n## What is a Hook?\nFirst off lets take a step back and consider what we actually mean by a \"hook\".\n\n## Designing a solution\n\nI had a few key requirements that my hook system needed:\n- I had to be able to hook into multiple parts of data processing, so there must be support for multiple hook \"types\". For example preprocessing, filtering, saving etc.\n- There needed to be a way to add system hooks to the codebase which should always run while also allowing custom hooks to be created which should not appear in source control.\n- All hook processes should be asynchronous via async/await so that hooks have the flexibility to run asynchronous tasks such as contacting external services etc.\n\n## Implementing the solution\nNow comes the actually JavaScript part... yay.\n\nI decided to create a `HookManager` class which would handle all hook related logic including registered hook types, adding hooks and running said hooks.\n\nThe base of this Class would look like this:\n\n```js\nclass HookManager {\n  constructor(){\n    this._hooks = {};\n  }\n\n  addHookType(hookTypeName) {\n    if !Object.keys(this._hooks).includes(hookName) {\n      this._hooks[hookName] = [];\n    }\n  }\n\n  addHook(type, name, function) {\n    if Object.keys(this._hooks).includes(type) {\n      this._hooks[type].push({\n        name: name,\n        function: function\n      });\n    }\n  }\n\n  async runHooks(type, data) {\n    if Object.keys(this._hooks).includes(type) {\n      for (const hook of this._hooks[type]) {\n        data = await hook.function(data)\n      }\n    }\n  }\n}\n```\n\nThen for my application I extend this base class to offer some application specific functionality:\n\n```js\nclass RedditIngestHookManager extends HookManager {\n  constructor(){\n    super();\n\n    this.addHookType(\"responseParse\");\n  }\n}\n```\n",
      "date_created": "2023-10-07T11:19:33.609Z",
      "date_updated": "2023-10-07T14:59:31.780Z",
      "description": "Creating a basic hook system in JavaScript",
      "featured": false,
      "id": "82154daa-f320-47e9-96b8-b2df866ffe8f",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "creating-a-basic-hook-system-in-javascript",
      "status": "idea",
      "title": "Creating a basic hook system in JavaScript",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        6
      ]
    },
    {
      "content": "## `tmux`",
      "date_created": "2023-10-07T11:19:33.761Z",
      "date_updated": "2023-10-14T21:53:39.647Z",
      "description": "Tips and tricks when using a headless Raspberry Pi",
      "featured": false,
      "id": "830860c6-b6f6-49d6-b5e4-673d064e50d5",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "tips-and-tricks-when-using-a-headless-raspberry-pi",
      "status": "idea",
      "title": "Tips and tricks when using a headless Raspberry Pi",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        11
      ]
    },
    {
      "content": "criteria:\n- open source\n- Node based\n- API driven\n- Good developer experience\n\nstrapi vs directus vs keystone ",
      "date_created": "2023-10-07T11:19:33.630Z",
      "date_updated": "2024-11-27T16:22:25.705Z",
      "description": "A high-level comparison of some popular open source headless CMS choices based on my opinion and experience.",
      "featured": false,
      "id": "9106c991-7921-4f03-b0b7-93413b03695c",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "headless-cms-comparison",
      "status": "idea",
      "title": "The Head to Head of Headless",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        8,
        9
      ]
    },
    {
      "content": "- build vs buy\n- dependency injection\n- npm publishing\n- lerna",
      "date_created": "2024-04-09T18:15:58.564Z",
      "date_updated": null,
      "description": "The knowledge and lessons I learnt from building my own Node.js framework.",
      "featured": false,
      "id": "91bc270d-d3f7-49f9-9afb-f32f6541f294",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "what-i-learnt-from-building-node-framework",
      "status": "idea",
      "title": "What I learnt from building a custom Node.js framework",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    },
    {
      "content": "<div class=\"j-callout\"><div class=\"j-callout__icon\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"j-icon\"><circle cx=\"12\" cy=\"12\" r=\"10\"></circle><path d=\"M12 16v-4\"></path><path d=\"M12 8h.01\"></path></svg></div><div class=\"j-callout__content\"><p>I originally wrote this essay for my A-Level Extended Project Qualification (EPQ) in 2019, so this essay reflects my opinion at that time.</p></div></div>\n\n\n## Introduction\n\nIn recent years the intelligence of computer systems has continued to grow exponentially, allowing them to achieve things once reserved for the world of science fiction. As algorithms begin to surpass human ability in more and more areas, worries about the future grow. \n\nArtificial Intelligence (AI) has already asserted its dominance in many fields. These systems have beaten the world’s best players of Chess and Go, analyse terabytes of data every second from internet traffic to weather data, and are even learning how to drive cars on the roads. \n\nIn the light of the first death at the hands of a self-driving car in March 2018, there has been a push to regulate AI development, from experts to the public alike, which has brought even more questions and concerns about this fields future to light. There are not only concerns about automation and the irreversible dependence we now have on technology, but lots of people – quite possibly influenced by science fiction works - worry that creating such independent intelligences could have serious implications for the human race, potentially destroying our society as computers outgrow our human intelligence and control, becoming super-intelligent.\n\nThis essay hopes to offer a judgement into whether fears for the rise of AI are justified; to explain why some misconceptions might lead to flawed fears, and outline the positive impacts and legitimate risks Artificial Intelligence poses in the future, and in the present.\n\n### What is meant by Artificial Intelligence (AI)?\n\nIt is important to outline the field of Artificial Intelligence and relevant key terminology within it before starting to explore the question, so as not to fall victim to the same misconceptions many have about AI, and ensure all arguments can start with a common foundation.\n\nArtificial Intelligence is a notoriously hard field to simplify into a single definition, partly because of the breadth held within this umbrella term, but also as put by McCarthy (1998) *“We cannot yet characterize in general what kinds of computational procedures we want to call intelligent.”*\n\nIn 2019, the Oxford English Dictionary defines Artificial Intelligence as *“the theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.”* This definition suffers from the same inadequacy pointed out by McCarthy, namely we can only be secure in a definition of Artificial Intelligence, if we agree on some definition or idea of intelligence, especially where it pertains to computers. Using the Oxford English dictionary again, intelligence is defined as *“The ability to acquire and apply knowledge and skill.”* This means we can try and synthesise a definition of an Artificially Intelligent system as: *A computer system capable of performing a task or making a decision by applying knowledge and past experience.*\n\n### Important Terms\n\n**Narrow AI**\n\nArtificial Narrow Intelligence (ANI) also known as “Weak” AI is the AI that exists in our world today. Narrow AI is AI that is programmed to perform a single task — whether it’s checking the weather, being able to play chess, or analyzing raw data to write journalistic reports. (Jajal 2018) \n\n**General AI**\n\nArtificial General intelligence (AGI) or “Strong” AI refers to machines that exhibit human intelligence. In other words, AGI can successfully perform any intellectual task that a human being can. This is the sort of AI that we see in movies like “Her” or other sci-fi movies in which humans interact with machines and operating systems that are conscious, sentient, and driven by emotion and self-awareness. (Jajal 2018)\n\n**Super-Intelligence**\n\nAn Artificial General Intelligence that vastly outperforms the best human brains in every significant cognitive domain. (Bostrom 2009)\n\n**Machine Learning**\n\nThe capacity of a computer to learn from experience, i.e. to modify its processing on the basis of newly acquired information. (Oxford English Dictionary)\n\n## Why are some views towards AI flawed?\n\n### The Problem of Anthropomorphization.\n\nAnthropomorphization is the attributing of human form or traits to something. In the context of AI *“something”* refers to a computer system, algorithm or perceived intelligent agent. This is a primary influence in people's misguided beliefs about Artificial Intelligence, as it builds up false notions of what these systems are, and indeed what they are actually capable of doing.\n\nFor example take personal assistants like Siri, Cortana and Alexa. There is a reason all of these technologies have been given human names. It provides a more authentic interaction between man and machine, and influences the user to trust the system. You could argue that this is why many robots designed to interact with people are given eyes, mouths and other discernible human idiosyncrasies too.\n\nIt is this characteristic, but reversed, which then also influence feelings towards Artificial Intelligence. Yudkowsky (2008) writes:\n\n*“Anthropomorphism leads people to believe that they can make predictions, given no more information than that something is an ‘intelligence’—anthropomorphism will go on generating predictions regardless, your brain automatically putting itself in the shoes of the ‘intelligence’.”*\n\nYudkowsky’s allusions to “predictions” here, are the prediction of what an agent will do, and how it will develop in the the future.\n\nHer point supports the idea that people build up fake notions of a systems intelligence and cognitive ability based more on what they project onto the agent, than the reality of the agent itself. This is the most common form of anthropomorphism that occurs with intelligent agents, which is to wrongly personifying a concept of will, meaning the perception that a machine has a rational behind its actions. \n\nThe training of Machine Learning algorithms often use a process where a set of “training data” is used to teach the algorithm how it should work correctly. Given the task to make an AI capable of recognizing cats, you might feed in thousands of images of cats telling the system if each image is a cat or not. Over time the system will learn what common identifiers indicate a cat being in the image, and then using its previous data can weigh up the likelihood of an brand new image being a cat. If you were to then feed in a picture of a elephant, your new algorithm is going to be useless at identifying it.\n\nAlthough a simple example, it does demonstrate that Narrow AI, the kind of AI currently in existence, still has no real intellect or rational, it is only able to perform what the user perceives to be a correct action because it has been trained to do it, by getting it wrong countless time.\n\nThe will of a AI is explored further by Yudkowsky later on in her paper, where she explains the “*Cheesecake Fallacy of Perception*”. Its premise is that - given the size of a cheesecake you can create is dependent on your intelligence - a super-intelligence could decide to build enormous cheesecakes, the size of cities. The question is, why would it want to build them? As she says, “*The vision leaps directly from capability to actuality, without considering the necessary intermediate of motive.*”\n\nTake this quote given by Stephen Hawking to the BBC:\n\n*“The development of full artificial intelligence could spell the end of the human race….It would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldn't compete, and would be superseded.”*\n\nWithout considering any additional context, this exhibits the “Fallacy of the Giant Cheesecake” as described by Yudkowsky. We jump from the capability: AI progresses to a general or super-intelligence which has the ability to superseded humanity; to the actuality: humanity would be wiped out by the intelligence; without considering the motives: that the intelligence would desire to exponentially grow, and wouldn’t care about it’s effect on humanity.\n\nThis example can show how anthropomorphization can lead to unrealistic view on how AI will develop and thus stoke the fears surrounding it. That incorrectly projecting human traits on to a system can lead to dramatic over-assumptions about its intelligence, which can have profound impacts into what we are willing to believe about how these systems will develop.\n\n### Seeing is Believing\n\n**The role of the media in influencing society's beliefs.**\n\n“Seeing is believing” - a common idiom meaning that to actually see or witness something, as opposed to simply being told about it, allows or will allow one to believe that it is true, or has occured.\n\nThe majority of people will have most, if any, of their exposure to Artificial Intelligence through media, whether that be news stories, films or books. Although not a problem in itself, it does often create unrealistic expectations for how AI will develop, and poses an interesting notion that some fears towards AI are in-fact inherited from the media around us.\n\nA common, and extreme, fear towards AI is the idea that “AI will rise up and take over the world.” The actual details vary drastically, some ideas suggest we will create a system that will out-evolve us, others say an AI will turn on it’s creator, or others say AI will simply kill us accidentally as a side effect of trying to carry out a task. Could it be a coincidence then, that some of the most popular movies concerning AI, “Terminator”, “I, Robot”, “Ex Machina” etc, all focus on dystopian elements of future Artificial Intelligence? Most are not as extreme as a large-scale extinctions, and few are as black and white as “people good, AI evil”, but all explore the idea that the development of AI could damage humanity and cause a significant negative impact both culturally and physically. It is worthwhile noting also, that nearly all AI portrayed in films are at general to super level intelligence, and not the at the realistic narrow AI stage we are at today.\n\nIn a story published by the New York Times in 2015, a study done by Michelle C.Pautz is explored, who investigated how watching the movies “*Argo*” and “*Zero Dark Thirty*”, affected the audiences opinions towards the government. She suggested that films can influence opinions on the topics the films explore. In her study, “*20 to 25% of participants changed their opinion - and generally more favorably - on a variety of questions asked about the government.*” Which matched the opinion the movies conveyed. Based on this, it wouldn’t be atall farfetched to deduce that if these movies can change audiences opinions towards government, movies about AI can change or influence people's thoughts towards AI.\n\nThis effect can be described with Transportation Theory, as explored by Melanie C. Green and Timothy C. Brock in their paper, The Role of Transportation in the Persuasiveness of Public Narratives (2000). They describe this effect as the *“extent that individuals are absorbed into a story or transported into a narrative word, may show effects of the story on their real-world beliefs.” *\n\nIt would be remiss to say all films depicting artificial intelligence do so negatively, take Wall-E for example, where the audience cannot help but feel compassion towards the protagonist, or Star Wars, with R2-D2 and C-3PO who are much beloved characters to the public. Indeed, it is also worth noting that not only do movies affect society, but society affects movies. Many movies explore current trends in thinking, picking apart the zeitgeist, and can also mirror the time in which they were produced.\n\nThe idea of the media influencing opinions can also be linked to the differences in opinion between those with experience or knowledge of technology, against those with little to no experience in the field, as the people most susceptible to external influences are likely the ones lacking in understanding.\n\nA study published in January 2019 (US Public Report) surveyed 2,000 Americans on their feelings towards AI.\n\nOn average 41% of those asked somewhat or strongly support the development of AI, as opposed to 22% who somewhat or strongly disagreed. As for the rest, 28% neither supported nor opposed it, and 10% did not know. It gets interesting though, when we consider respondents Computer Science experience in relation to their answers. Those with experience or degrees in Computer Science were on average much more likely to support developing AI. 31% of those with no experience, somewhat to strongly supported AI development compared to the 58% of those with experience. These results could suggests that people with more knowledge and background in the field are more trusting of AI, or better think of its possible advantages. That they feel it better to continue the research and progression of advanced AI systems, which could indicate that as a whole, we should be less skeptical of fearful of the future of AI, if those who are most likely more informed believe its development to be worthwhile.\n\n### Automation\n\n“Robots will take all our jobs.” This phrase has existed in different variations for many years. It wasn’t always “robots” explicitly. In the past it has been applied to many forms of technology. “Luddites” - a term used to describe those opposed to new technology - draws its origin from the early 19th century, where groups of English textile workers worried about how new machinery in cotton and wool mills would affect employment, took to protesting and marching, destroying these machines. Now in the present, we clearly see the benefit of these technological advancements, such as adoption of the automobile (car), which many at the time worried were a danger and menace to roads, but now the world could barely function without them. There was once a time when flint was the cutting edge of cutting edge technology, when man’s dream to fly was, just that, a dream. There is a common phrase, to “fear the unknown”, clearly this outlook can be seen in the wariness some poses to trust technological advancements, and fears towards the rise of Artificial Intelligence and automated systems are no different.\n\nAutor (2015) states *“journalists and even expert commentators tend to overstate the extent of machine substitution for human labor and ignore the strong complementarities between automation and labor that increase productivity, raise earnings, and augment demand for labor.”* His point can also link back to the previous section in which it is made apparent that the media can affect our perceptions of technology, which is especially prevalent in the topic of automation. A quick search for news on “automation” gives, among others, these headlines:\n\n*Baby, Baby, Baby, Where Did Our Jobs Go? How Automation Will outsource everything to machines (CleanTechica)*\n\n*Automation is Coming for American Workers, Says Mayor Pete Buttigieg (NowThisNews)*\n\n*Automation threatening 25% of jobs in the US, especially the 'boring … (CNBC)*\n\n(*Google News Tab, first page only. Search on 28/01/2019*)\n\nThere is a clear theme here. It is not to say that these concerns and points raised are totally invalid, they are not and it would be irresponsible to not to convey this, as openly accepted by Autor: “*In 1900, 41 percent of the US workforce was employed in agriculture; by 2000, that share had fallen to 2 percent.”* which shows technology can still have a definite effect on the employment of large groups of people. But society adapts.\n\nIn a economics report done by PricewaterhouseCoopers (PwC), it is estimated that although 7 million existing jobs could be displaced, around 7.2 million jobs could be created, meaning net employment will not change across the UK. However, John Hawksworth (PwC’s chief economist) did admit *“the distribution of jobs across sectors will shift considerably in the process.”* and the report also states *“Historically, rapid technology change has often been associated with increases in wealth and income inequality, so it’s vital that government and business works together to make sure everyone benefits from the positive benefits that AI can bring” *showing that indeed the fears toward Automation, and more intelligent AI systems taking jobs are not totally unjustified.\n\nThe primary issue with automation therefore, is not necessarily iminent unemployment, but adapting to the new roles and challenges these advancements create, which if handled effectively by companies and governments can be addressed. If these risks and concerns are not addressed in the coming years however, automation due to AI will start to become a definite problem, in which there is the potential for millions of jobs to be lost. These advancements will also increase the wealth inequality between the rich minority and the working class majority, which could even lead to the need for widespread Universal Basic Income or other such systems.\n\n## Why are some fears for AI justified?\n\n### Hanlon’s Razor and Algorithmic Bias\n\n**\"Never attribute to malice that which is adequately explained by stupidity.” - Robert J. Hanlon**\n\nI originally came across this phrase in relation to computers from an educational video by Tom Scott, where he used it in relation to a bug in a mobile game, which gave the developer access to a users entire email account. The developer came under heavy criticism, but was adamant it was an error, and applied a patch to solve the problem. No evidence of malpractice was found.\n\nHere we have an example of a problem in technology, where the error, the weak link, is the human behind it.\n\nHanlon’s Razor can be applied to the field of Artificial Intelligence, namely if we take “malice” to mean a purposely destructive act by an AI, and take “stupidity” to mean humanity’s actions.\n\nAs mentioned previously, a common approach to machine learning is to use what is know as “training data”, in which sets of data are used to train a system in the task it is to perform. This creates issues when applying AI to the real world situations. In its simplest form: AI is only as perfect as the data it’s trained on. The problem? Humans are far from perfect.\n\nIn 2015, Amazon had to abandon an AI algorithm trained to help recruitment by filtering hundred of applications. The problem, overlooked by the team working on it at the time, was that the AI was fed with predominantly male applications, as this was the higher average. They found the algorithm started to penalise applications with the word “women” in them, this was then changed, but it became clear the AI wasn't working as desired and the project abandoned.\n\nThis isn’t the only incident of biased AI. There have been multiple reports over the last few years of racially prejudiced systems. One algorithm used to help police in several US states to predict where and when crimes might occur, was found to unfairly target certain neighborhoods with higher numbers of racial minorities. This was speculated to be because the algorithm was trained on reports from human police officers, which still can hold the same prejudice, meaning the system was effectively being trained to discriminate. The severity of this problem is demonstrated in a quote from IBM’s website, a leader in AI technology research, where they say: *“Bad data can contain implicit racial, gender, or ideological biases. Many AI systems will continue to be trained using bad data, making this an ongoing problem.”* going on to say algorithmic bias “*occurs in the data or in the algorithmic model. As we work to develop AI systems we can trust, it’s critical to develop and train these systems with data that is unbiased and to develop algorithms that can be easily explained*.”\n\nThis point is less clear cut than the some of the other points made in this essay. It is clear that AI in of itself is unlikely to pose a threat to humanity, certainly in the present and near future, meaning again fears about AI (in isolation of itself) are unfounded. However, It does raise a legitimate risk and a major concern in the development of Artificial Intelligence, that of algorithmic bias. The fact these algorithms can be trained with implicit biases, that AI designed to improve human life and expand our abilities, might end up suffering from the exact same problems and pitfalls as their creators.\n\n### The use of AI in weaponry.\n\nOn January 9th 2017, the US Department of Defense announced a successful test, and released footage, of a “Micro-Drone swarm”. 103 Small drones deployed from fighter jets were able to act as an autonomous swarm, with “collective decision-making capabilities, adaptive formation flying, and self-healing.” This advancement has serious implications for the future of warfare, and the role of AI systems within it.\n\nLethal Autonomous Weapons Systems (LAWS) is the term given to technology which is capable of independently carrying out defensive, or offensive, military tasks. Current systems in deployment still rely on humans for their final decision, but the concern is that eventually these systems will be fully autonomous, with the capability to decide whether to engaging an enemy with no intervention from any human operators. The development of these independent units has already led to many protests and open letters to governments around the world calling for an end to this new arms race. One such organisation, the Campaign to Stop Killer Robots argue this technology *“crosses a moral threshold. As machines, they would lack the inherently human characteristics such as compassion that are necessary to make complex ethical choices.”* Many feel, and quite possibly correctly, that these systems should not be given this level of responsibility. That to do so would make it harder to get justice for victims, as laws are currently unclear on who is held accountable for the actions of an AI. As put by historian Matt Whitman on drone swarms: *“If we’re just holding xbox controllers halfway around the world… on the human level it reduces one of our biggest checks in engaging in violence.”* We are much more likely to get physically involved in a conflict, if those involved are out of harm's way, which links to the arguments made by the Campaign to Stop Killer Robots, who also point out such remote weapons “shift the burden of conflict even further onto the civilians” as it would still be these who suffer most with both sides engaging with this technology.\n\nIt is not just dedicated opposition groups who have made their views clear either. In 2018, many Google employees signed an open letter to Google’s CEO, Sundar Pichai, and staged a walkout, voicing their outrage at project Maven, a partnership between Google and the American government to produce AI weaponry. They demanded that the company should withdraw from the contract, and then urged it to publicly state it would never help develop AI weaponry, pointing out their actions seem to contradict a famous section of the companies code of conduct, “don't be evil.” This caused Google to decide to withdraw from the contract when it expires this year.\n\nThese protests towards the use of Artificial Intelligence in weaponry, especially by those working in the industry, highlight the severity of the problem, and seem to suggest that as of now, there is still no adequate regulations and agreements to ensure these systems will be safe and moderated as development continues into the future.\n\n## Why we should embrace the future of AI.\n\nMuch of this essay has been focused upon the potential risks that AI raises, those that are already happening, and the common misconceptions which unfairly shape people's perceptions of AI. What has not been covered, are the true benefits that Artificial Intelligence could provide to society and humanity as a whole. It is also easy by focusing so much on the future, to overlook the fact that AI is already present in many technologies today, and its positive effect is felt all over the world, everyday.\n\n### Consumer Market\n\nA common and popular application in the present, is the development of personal assistants and natural language processing, evident in products such as Google Home and Alexa, but also incorporated into the rest of our technology, like Siri, Cortana and Ok Google. These systems have already begun to change how we interact with our technology, allowing for a more natural and personal connection with our devices. \n\nA less obvious application of machine learning and Artificial Intelligence techniques in today's consumer products are those of recommendation algorithms. Amazon, Netflix, Google and many more use AI to personalise consumers feeds with products thought to be more appealing to them, using intelligence to better enhance user experience and the usefulness of their products.\n\nHowever, Rijsdijk et al,(2007) conducted tests into consumer satisfaction on intelligent products, stating: *“Our results show that consumers do not appreciate intelligent products for their intelligence itself, but because of the relative advantage and compatibility that they deliver.” *which although not contradicting the idea that Artificial Intelligence in consumer products is a positive, does show that it is not AI which is directly having the impact, but its effect, which is to be expected. People do not value their phones simply because they are computers, but for what they enable them to do. So while based off this study we see consumers do not explicitly value Artificial Intelligence in their products, the positive effect of AI on these products is clearly apparent.\n\n### Medical Diagnosis and Treatment\n\nArtificial intelligence has started to revolutionise the field of medicine, especially in diagnosis. Using image recognition technology, systems are now able to predict cancer growth upto 20 years before human scientist could. As quoted by the BBC, from Caranagna et al (2018) *\"This new approach using AI could allow treatment to be personalised in a more detailed way and at an earlier stage than is currently possible, tailoring it to the characteristics of each individual tumour and to predictions of what that tumour will look like in the future.\" *\n\nAI is also being applied to help those who have been partially or completely paralyzed. Using special sensors implanted in the brain it is now possible for Artificial Intelligence to allow for patients to move robotic arms, or indeed their own, by measuring electrical signals from the brain. This involves asking the patient to think about moving their arms in different way, AI software then proceeds to learn what electrical signals from the brain represent these movements, and then once the system has gathered enough data, it can scan the brain and when it detects this signal, can either move a robotic arm, or then send impulses to electrodes on the patient's arm which trigger the muscles to act. This application of AI is at the cutting edge of development, and shows the potential for this technology in the next few years to not only progress the field of computers and technology, but enhance the human body as well.\n\n### Keeping humans out of danger\n\nA common use of robots already, is to replace particularly dangerous or hazardous jobs people would have to have previously done. The most obvious application is in warfare, which although already discussed as a prime area of concern in the development of AI, does potentially lead to less human fatality, or it could be argued, simple shifts this to the more vulnerable. \n\nOne real positive application of AI in dangerous situations however, is in disaster response. It has been hypothesised that by using drone-swarms or nano-robots it is possible to deploy these at a disaster zone and have them work autonomously, scanning the area for potential humans remaining, co-ordinating their actions. This could be especially useful in post-earthquake zones where buildings are liable to collapse, or during fires, as this reduces the risk rescuers are taking, which could therefore end up preserving more human lives as a consequence.\n\n## Conclusion\n\nAs shown throughout this essay, there are both positive and negative outlooks on Artificial Intelligence. We see its use in everyday life, like in cancer diagnosis and recommendation algorithms, and we can see the promises it offers in pushing human technology further than it has ever been. However, the harm AI could cause has also been explored, both in the workplace, with the rise of Automation, and on the battlefield with the continuing development of LAWS and other weaponry with the aim of automating warfare and defense. We have also seen, that there is still ambiguity around the field of Artificial Intelligence itself, and that on average there are many misconceptions, misunderstandings and plain mistruths about what Artificial Intelligence is, what it can and can’t do, and how it could affect humanity in the years to come.\n\nIt should be apparent, that scaremongering that AI will “rise up and kill us all.” is almost definitely incorrect, but it would also be wrong to dismiss all threats that AI could cause. To underestimate potential negative impacts AI could have is far more dangerous, and could lead to irreversible consequences. Take the warning of PwC on automation. They outline that AI automation will radically change the job market, and believe based on their study that it won't cause the mass job loss people panic about. However, they are quick to point out this depends on how companies and governments respond: *“it’s vital that government and business works together to make sure everyone benefits from the positive benefits that AI can bring.”*\n\nThis is also the case with the Campaign to Stop Killer Robots. They propose we must *“Retain meaningful human control over targeting and attack decisions by prohibiting development, production, and use of fully autonomous weapons. Legislate the ban through national laws and by international treaty.”*\n\nHere they are not campaigning for the total eradication of AI in weaponry, as they realise it is potentially futile to protest for a complete ban, but they wish to ban “fully” autonomous weaponry. They believe there still should be human intervention (“meaningful human control”), which means humans overseeing this technology as it develops and during its use, a view which is also important in the emergence of algorithmic bias, that a lack of oversight and regulation of these systems is likely the most severe danger of Artificial Intelligence going forward,.\n\nIn a report given to the European Council, Häggström (2017) makes the argument for Rational Optimism, towards the AI future. This is having a “*epistemically well-calibrated view of the future and its uncertainties, to accept that the future is not written in stone, and to act upon the working assumption that the chances for a good future may depend on what actions we take today.”*\n\nThis I think, is the best and most productive way of approaching the development of Artificial Intelligence systems going forward. There are a multitude of potential benefits that AI can offer to society that could change not only how we live and work, but also how we fundamentally think about the world around us. There are also many dangers, which could lead to the unemployment of millions or, worst case scenario, threaten the very continuation of the human race.\n\nSo, should we fear AI? No we should not. Not if we are willing to collectively work together now to mitigate the risks AI could pose in the future. Maybe a more suitable question would be: Should we fear humanity?\n\n## Bibliography\n\nO, Häggström (2017) Remarks on Artificial Intelligence and Rational Optimism\n\n[http://www.europarl.europa.eu/RegData/etudes/IDAN/2018/614547/EPRS_IDA(2018)614547_EN.pdf](http://www.europarl.europa.eu/RegData/etudes/IDAN/2018/614547/EPRS_IDA(2018)614547_EN.pdf)\n\nJ, McCarthy (1998) What is Artificial Intelligence?, Stanford University CA 94305\n\n[http://cogprints.org/412/2/whatisai.ps](http://cogprints.org/412/2/whatisai.ps)\n\nT, Jajal (2018) Distinguishing between Narrow AI, General AI and Super AI\n\n*[https://medium.com/@tjajal/distinguishing-between-narrow-ai-general-ai-and-super-ai-a4bc44172e22](https://medium.com/@tjajal/distinguishing-between-narrow-ai-general-ai-and-super-ai-a4bc44172e22)*\n\nN, Bostrom (2009) Superintelligence Answer to the 2009 EDGE QUESTION: “WHAT WILL CHANGE EVERYTHING?”\n\n*[https://nickbostrom.com/views/superintelligence.pdf](https://nickbostrom.com/views/superintelligence.pdf) *\n\nE, Yudkowsky (2008) Artificial Intelligence as a Positive and Negative Factor in Global Risk, MIRI\n\n[https://intelligence.org/files/AIPosNegFactor.pdf](https://intelligence.org/files/AIPosNegFactor.pdf) \n\nC, Paultz (2015) Argo and Zero Dark Thirty: Film, Government, and Audiences\n\n[https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/argo-and-zero-dark-thirty-film-government-and-audiences/889B13ED0B53B2DF7C09372D4ACCECE5](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/argo-and-zero-dark-thirty-film-government-and-audiences/889B13ED0B53B2DF7C09372D4ACCECE5) \n\nC, Green and T, Brock. The Role of Transportation in the Persuasiveness of Public Narratives Ohio State University \n\n[http://www.communicationcache.com/uploads/1/0/8/8/10887248/the_role_of_transportation_in_the_persuasiveness_of_public_narratives.pdf](http://www.communicationcache.com/uploads/1/0/8/8/10887248/the_role_of_transportation_in_the_persuasiveness_of_public_narratives.pdf) \n\nD, Autor (2015) *Why Are There Still So Many Jobs? The History and Future of Workplace Automation,* Journal of Economic Perspectives—Volume 29, Number 3—Summer 2015—Pages 3–30\n\n[https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.29.3.3](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.29.3.3) \n\nRijsdijk et al, (2007) Product intelligence: its conceptualization, measurement and impact on consumer satisfaction.\n\n[https://link.springer.com/content/pdf/10.1007%2Fs11747-007-0040-6.pdf](https://link.springer.com/content/pdf/10.1007%2Fs11747-007-0040-6.pdf) \n\nCaranagna et al (2018) Detecting repeated cancer evolution from multi-region tumor sequencing data.\n\n[https://www.nature.com/articles/s41592-018-0108-x.epdf](https://www.nature.com/articles/s41592-018-0108-x.epdf) \n\nUS Public Report: [https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/general-attitudes-toward-ai.html](https://governanceai.github.io/US-Public-Opinion-Report-Jan-2019/general-attitudes-toward-ai.html)\n\nPwC Report: [https://www.pwc.co.uk/press-room/press-releases/AI-will-create-as-many-jobs-as-it-displaces-by-boosting-economic-growth.html](https://www.pwc.co.uk/press-room/press-releases/AI-will-create-as-many-jobs-as-it-displaces-by-boosting-economic-growth.html)\n\nStephen Hawking to BBC: [https://www.bbc.co.uk/news/technology-30290540](https://www.bbc.co.uk/news/technology-30290540)\n\nIBM on AI bias: [https://www.research.ibm.com/5-in-5/ai-and-bias/](https://www.research.ibm.com/5-in-5/ai-and-bias/)  \n\nNew york times on C, Paultz [https://op-talk.blogs.nytimes.com/2015/02/04/how-movies-can-change-our-minds/](https://op-talk.blogs.nytimes.com/2015/02/04/how-movies-can-change-our-minds/) \n\nTom Scott (Hanlon’s Razor)\n\n[https://www.youtube.com/watch?v=cDZjm4f9CEo](https://www.youtube.com/watch?v=cDZjm4f9CEo) \n\nCampaign to stop killer robots: [https://www.stopkillerrobots.org/learn/](https://www.stopkillerrobots.org/learn/) \n\nM, Whitman on AI swarm: [https://www.nodumbquestions.fm/listen/2017/2/10/ndq003-drones-and-bears](https://www.nodumbquestions.fm/listen/2017/2/10/ndq003-drones-and-bears) (12:00 - 12:53)",
      "date_created": "2023-10-07T11:19:33.742Z",
      "date_updated": "2023-10-15T21:06:32.767Z",
      "description": "In a world where computers continue to surpass human ability in more and more areas, are fears towards the rise of AI justified?",
      "featured": true,
      "id": "95a54228-0a8d-46ec-9e4b-667b88238b65",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "should-we-fear-ai",
      "status": "published",
      "title": "Should we fear AI?",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        2
      ]
    },
    {
      "content": "This is not an exhaustive guide meant for beginners to Linux and dual booting, it is more like a breif reference.\n\n## Prerequisites\n- USB installers for Windows and Ubuntu\n\n## Windows Setup\n- Install and setup Windows 11 as normal.\n- Open 'disk partition manager'  and shrink the windows partition to make space for Ubuntu.\n\n## Ubuntu Partition Setup\n- Boot into the live USB installer\n- Open 'Software and Updates' and enable the community maintained source\n- Run `sudo apt install partitionmanager`. The default \"Disks\" and \"gParted\" programs for manging device and partitions do not support created LUKS volumes well, so we'll use this tool. It's also possible to just use the command line if you know the commands to run.\n- Open partition manager\n    - Create a 500MiB ext4 partition which will be used for linux boot.\n\t- Create a LVM2 PV partition with the remaining space, making sure you use the encrypt with LUKS option.\n    - Create a volume group for this partition.\n\t- Within the volume group: \n    \t- Create a `70GB` `ext4` root partition.\n\t\t- Create a swap partition. This should be equal to the amount of ram in your system\n\t\t- Create a `ext4` home partition with the remaining space\n\n## Ubuntu Install\nBefore starting the ubuntu installer, make sure the LUKS volume is unlocked so its acccesible to the installer.\n- Open the installer\n- Run though all options as required, when setting up the installation type click \"Something else\"\n- Select the boot, root, swap and home partitions created eariler.\n- For the bootloader installation, use the existing parition created by Windows, likely called \"Windows Boot Loader\".\n- Install",
      "date_created": "2023-10-09T11:39:49.421Z",
      "date_updated": "2024-05-13T16:42:29.233Z",
      "description": "A guide on how to dual boot Ubuntu with LUKS and windows 11 on a single disk.",
      "featured": false,
      "id": "b075f2b5-9d66-4e46-bd61-17992d4f6eb0",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "ubuntu-23-04-windows-11-dual-boot",
      "status": "idea",
      "title": "How to dual boot Ubuntu 22.04 and Windows 11 with encryption",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        13
      ]
    },
    {
      "content": "## Criteria\n-\n\n## Top Options\n\n### Verdant (https://verdant.dev) 🤔\nGreat focus on simplicity over technical perfection, but lacks client-side encryption, maturity and the docs look fairly good but not perfect.\n\n- ✅ Great focus on simplicity and usablity over perfection\n- ✅ Docs looks farily well detailed\n- ✅ Nice project manifesto, ethos etc\n- ✅ Active development and maintainance \n- ❌ No encryption support?\n- ❌ Strong focus on React. Reactivity seems to be built around React hooks specifically, but may also be built into vanilla packages?\n\n### Custom Solution (Localful) ✅ \nNot the best solution for efficiently building an application, but offers many opportunities\nfor personal growth and learning. This also allows me to meet all my requirements and gives\nme complete control over my tech stack and data.\n\n- ✅ Able to build the exact features I want (encryption, no CRDTs to manage etc)\n- ✅ Full control and visbility into code and application data\n- ✅ Opportunity to learn lots during development and maintaince\n- ❌ Lots of time and effort required when lots of solutions already exist\n- ❌ Would have to trust my own code for security\n\n### Evolvu (https://www.evolu.dev/) 🤔\nProbably the best option for using CRDTs\n\n- ✅ SQLite in browser gives power of SQL, relationships etc\n- ❌ SQLIte must run full database in browser?\n\n\n### ElectricSQL\nPotential option for the future, but doesn't support client-side encryption.\n\n- ✅ Polished docs based on a quick look \n- ✅ Use of postgres on backend and allows self-hosting \n- ❌ No support for client-side encryption, but it is 'on their internal roadmap': https://github.com/electric-sql/electric/discussions/556.\n\n## Other Options\n\n### PouchDB (https://pouchdb.com/) ❌\n- ✅ Established and battle tested, looks to be built off well defined specifications\n- ❌ There is a PouchDB server allowing for a self-hostable Node/Express server, but it is not well maintained and is not recommended for production.\n- ❌ You can use CouchDB which has lots features like built-in user support, however there would be a steep learning curve in setting this up and running in production. In this scenario, the tech stack would manage me rather than me managing the tech stack.\n\n### VLCN \n\n### TinyBase\n\n### InstantDB (https://www.instantdb.com/) ❌\n- ❌ In preview state so not production ready and won't look into more at this time.\n\n### Replicache ❌\n- ✅ Documentation looks good\n- ✅ Has pricing model, but is reasonable and based off revenue & funding for companies.\n- ❌ It looks like backend needs have knowledge of data, so doesn't support client-side encryption.\n\n### WatermelonDB (https://watermelondb.dev) ❌\nFocus on React native makes it a promising looking option for mobile development. The docs suggest LokiJs as an adapter for the browser however, which doesn't look like a good option.\n\n- ❌ For web usage the docs appears to suggest 'LokiJS' (https://github.com/techfort/LokiJS) which looks to be in-memory and has no commits for two years. The in-memory nature likely makes it unsutable for my use case, where loading all data into memory would not be feasible.\n\n### RxDB (https://rxdb.info/) ❌\nNot a viable option due to pricing model. Could potentially use the open source parts of the library fine, but the pricing has put me off investing any time in looking into the project.\n\n- ✅ Looks quite polished and mature at a surface level\n- ✅ Docs look good at a surface level\n- ❌ Lots of feature not open source and require buying a prohibitively expensive license (€764 per year for 1 project, no fallback license etc). I completely agree that open source maintainers deserve to be paid for their work, but this pricing model makes the project fundermentally unsuitable for my use case so I didn't feel the need to dig any further into pros and cons.\n\n## Conclusion\nThe best option for me right now is building Localful, despite the fact that this is significantly more effort than using an existing library. It gives me a great opportunity to learn not things right now and means I will be in compelte control of my tech stack and data.\n\nIf in the long run I decide that the effort in building and maintining my own library gets too much, the best option for me so far appears to be Verdant. I would have to look into what data is sent to the server and how the sync works first though, becuase if Verdant fundementally can't support client-side encryption then it might not be usable for my user cases.",
      "date_created": "2024-01-22T12:54:31.978Z",
      "date_updated": "2024-11-27T16:21:19.070Z",
      "description": "How I picked a storage option/platform for my local-first software.",
      "featured": false,
      "id": "bf9be7d7-fd65-4ac0-b009-a9f6d650ce7b",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "picking-a-local-first-storage-option",
      "status": "idea",
      "title": "Picking a Local First Storage Option",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    },
    {
      "content": "First and foremost this guide is opinion based on my reading on the topic and current experience with building APIs, it is not meant to be taken as gospel or a declaration of \"best practises\".\nI hope to share the knowledge I've gained while building APIs through trial and lots of error, in the hopes that you might find my advice useful and it may help you when deciding how to build an API.\n\n\n## Use layers to seperate \nThe means seperating out your HTTP handlers from buisness logic and the database. A common pattern here is to use \"controllers\" or \"adapters\" to manage the API itself, for example HTTP controllers for a standard REST API, and then to use \"services\" for buisness logic and database interaction.\nThe key here is to seperate concerns, your buisness logic and database services shouldn't care that your building a REST API. This is helpful as it means you can re-use your services in multiple situations, for example if you provide a REST API and websockets these can both have different controllers but use the same services for interacting with yout data because the service is generic.\n\n## Group functionality by purpose, not by type\n",
      "date_created": "2023-10-07T11:19:33.644Z",
      "date_updated": "2023-10-14T21:54:50.153Z",
      "description": "A collection of good practices and my opinions on how to build a API, including how you should structure the application itself and how you should build your API interface.\n\n",
      "featured": true,
      "id": "c18b6fdf-8013-4bc2-af70-245d4b2f516b",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "how-to-build-a-good-api",
      "status": "draft",
      "title": "How to build a good API",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": [
        7
      ]
    },
    {
      "content": "Should you learn to invent the wheel?",
      "date_created": "2024-05-13T16:51:18.345Z",
      "date_updated": "2024-11-27T16:19:25.863Z",
      "description": "The answer is yes. The real question is, when should you build the wheel and when should you drive the car?\n\nDevelopers reinventing the wheel is a well know situation, and something I've been guilt of many times. Solving solved problems is often wasted effort, but when used as a tool for learning it can be informative and rewarding.  \nHow can you decide which wheels to reinvent, and how to balance your desire to learn with your desire to build things?\n\n",
      "featured": false,
      "id": "c1a64a36-049a-4b84-8fdd-b4eaa5e8ee73",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "should-you-learn-to-invent-the-wheel",
      "status": "draft",
      "title": "Should you learn to invent the wheel?",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    },
    {
      "content": "The problem with superstar developers",
      "date_created": "2024-05-13T16:41:46.746Z",
      "date_updated": "2024-11-27T16:22:54.444Z",
      "description": "The problem with superstar developers",
      "featured": false,
      "id": "c96d3428-018b-4283-9436-e59baf204d9a",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "the-problem-with-superstar-deelopers",
      "status": "draft",
      "title": "The problem with superstar developers",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    },
    {
      "content": "\n\n## Nothing works\n\n## Why bother?\n\n## Do something about it\n",
      "date_created": "2023-10-14T11:51:43.968Z",
      "date_updated": "2023-10-14T11:53:54.095Z",
      "description": "The importance of progressive enhancement in a user focused web.",
      "featured": true,
      "id": "db3d2d6e-c401-4868-9271-7600d9b0a829",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "web-without-javascript",
      "status": "draft",
      "title": "A web without Javascript",
      "date_published": null,
      "related_blog_posts": [
        1,
        2
      ],
      "related_projects": [
        1
      ],
      "tags": [
        14
      ]
    },
    {
      "content": "In the world of social media, algorithms and endless content it's important to leave space for boredom.",
      "date_created": "2024-05-13T16:44:27.958Z",
      "date_updated": "2024-11-27T16:22:33.255Z",
      "description": "In the world of social media, algorithms and endless content it's important to leave space for boredom.",
      "featured": false,
      "id": "fd3da87e-c0d6-48e8-aa1d-1924eca6ed46",
      "metadata_description": null,
      "metadata_tags": null,
      "slug": "leave-space-for-boredom",
      "status": "draft",
      "title": "Leave space for boredom",
      "date_published": null,
      "related_blog_posts": [],
      "related_projects": [],
      "tags": []
    }
  ]
}